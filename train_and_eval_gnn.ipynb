{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c8b2c2",
   "metadata": {},
   "source": [
    "## GOAL: predict whether an edge (interaction) between two proteins should be included in a pathway (label 1) or not (label 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c50aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import EdgeConv, NNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae6dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7030fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 2\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f94abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to CUDA\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45e575",
   "metadata": {},
   "source": [
    "### Data Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7975f71",
   "metadata": {},
   "source": [
    "**Pytorch Geometric `DataLoader` object from saved data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f8a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique nodes: 17407\n"
     ]
    }
   ],
   "source": [
    "union_ppi = pd.read_csv('processed-data/union_ppi.txt', sep='\\t', header=None)\n",
    "unique_nodes = set(union_ppi[0].tolist() + union_ppi[1].tolist())\n",
    "label_id_map = {label: idx for idx, label in enumerate(sorted(unique_nodes))}\n",
    "num_nodes = len(label_id_map)\n",
    "print(f\"Total unique nodes: {num_nodes}\")\n",
    "\n",
    "inv_label_map = {idx: label for label, idx in label_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60700cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = torch.load('dataset.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ce6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data objects: 820\n",
      "\n",
      "Data object 0:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 1:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 2:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 3:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 4:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of data objects:\", len(data_list))\n",
    "\n",
    "for i, data in enumerate(data_list[:5]):\n",
    "    print(f\"\\nData object {i}:\")\n",
    "    print(\"  Node features (x) size:\", data.x.size())\n",
    "    print(\"  Edge index size:\", data.edge_index.size())\n",
    "    print(\"  Edge attributes size:\", data.edge_attr.size())\n",
    "    print(\"  Edge labels (y) size:\", data.y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a6c6a",
   "metadata": {},
   "source": [
    "### Class Weight Calculation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e493d",
   "metadata": {},
   "source": [
    "- Calculate the weight for the positive class to handle class imbalance\n",
    "- needed since the number of negative samples (non-selected edges) is much higher than positive samples (selected edges)\n",
    "- weighting the **loss function** helps the model to learn from the minority class effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8bddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class weight: 7362.594285968186\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_weights(data_list):\n",
    "    # concat all labels into single tensor\n",
    "    y = torch.cat([data.y for data in data_list]).cpu().numpy()\n",
    "    # count the number of pos and negative samples\n",
    "    num_positive = y.sum()\n",
    "    num_negative = len(y) - num_positive\n",
    "    # calculate the weight --> ratio of negative samples to positive samples\n",
    "    # so that loss function balances the contribution of both classes\n",
    "    pos_weight = torch.tensor([num_negative / (2 * num_positive)]).to(device)\n",
    "    return pos_weight\n",
    "\n",
    "pos_weight = calculate_class_weights(data_list)\n",
    "print(f\"Positive class weight: {pos_weight.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b024a",
   "metadata": {},
   "source": [
    "### Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e89fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(data_list))\n",
    "test_size = len(data_list) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c900326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, test_dataset = random_split(data_list, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc3376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the file names from the train split\n",
    "# train_indices = train_dataset.indices \n",
    "# train_file_names = [data_list[idx].file_name for idx in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c009d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_file_names to a txt file\n",
    "# with open('train_files.txt', 'w') as f:\n",
    "#     for fname in train_file_names:\n",
    "#         f.write(f\"{fname}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37eacf6",
   "metadata": {},
   "source": [
    "### Train-test split: from existing train split file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1f9fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 656 graphs; testing on 164 graphs.\n"
     ]
    }
   ],
   "source": [
    "with open('normalized_train_files.txt') as f:\n",
    "    train_files = set(f.read().splitlines())\n",
    "\n",
    "#Partition data_list\n",
    "train_dataset = [data for data in data_list if data.file_name in train_files]\n",
    "test_dataset  = [data for data in data_list if data.file_name not in train_files]\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} graphs; testing on {len(test_dataset)} graphs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab2737",
   "metadata": {},
   "source": [
    "### Edge Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffd1b2",
   "metadata": {},
   "source": [
    "- technique that oversamples the positive edges to address class imbalance\n",
    "- duplicate positive edges in dataset to increase representation during training - so that the model sees more examples\n",
    "- oersampling helps the model to better learn the characteristics of the minority class (selected edges), improving its ability to classify them correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c7763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_sampling(data_list, sampling_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Oversample edges from the minority class (positive edges).\n",
    "    Args:\n",
    "        data_list: List of PyG data objects.\n",
    "        sampling_ratio: Ratio of minority class edges to add.\n",
    "    Returns:\n",
    "        Augmented data_list with oversampled positive edges.\n",
    "    \"\"\"\n",
    "    augmented_data_list = []\n",
    "    for data in data_list:\n",
    "        y = data.y.cpu().numpy()\n",
    "        # get the indices of positive and negtive edges\n",
    "        positive_indices = np.where(y == 1)[0]\n",
    "        negative_indices = np.where(y == 0)[0]\n",
    "        # oversample positive edges\n",
    "        num_positive = len(positive_indices)\n",
    "        # fraction of +ve edges are randomly sampled with replacement\n",
    "        num_samples = int(sampling_ratio * num_positive)\n",
    "        # stores the indices of the sampled positive edges\n",
    "        sampled_indices = np.random.choice(positive_indices, num_samples, replace=True)\n",
    "        # connectivity information (source and target nodes) for the sampled edges:\n",
    "        sampled_edge_index = data.edge_index[:, sampled_indices]\n",
    "        # edge features for sampled edges:\n",
    "        sampled_edge_attr = data.edge_attr[sampled_indices]\n",
    "        # labels for sampled edges:\n",
    "        sampled_y = data.y[sampled_indices]\n",
    "        # connectivity information is updated by concatenating the original edges and the sampled edge:\n",
    "        data.edge_index = torch.cat([data.edge_index, sampled_edge_index], dim=1)\n",
    "        # edge features are updated by concatenating the original features and the sampled features:\n",
    "        data.edge_attr = torch.cat([data.edge_attr, sampled_edge_attr], dim=0)\n",
    "        # labels are updated by concatenating the original labels and the sampled label:\n",
    "        data.y = torch.cat([data.y, sampled_y], dim=0)\n",
    "        augmented_data_list.append(data)  \n",
    "    return augmented_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3c682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply edge sampling to the training dataset\n",
    "train_dataset = edge_sampling(train_dataset, sampling_ratio=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f2d34",
   "metadata": {},
   "source": [
    "### Make DataLoader:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25b273",
   "metadata": {},
   "source": [
    "- for batching and shuffling data\n",
    "- feeds data into model during training and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005c6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe1879",
   "metadata": {},
   "source": [
    "### Model Definition: using `EdgeConv` and `NNNConv` layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82375eea",
   "metadata": {},
   "source": [
    "- define GNN for edge classification \n",
    "- architecture designed to capture both node + edge features - needed for accurately classifying edges in PPI network\n",
    "- use mlps to transform node + edge features into higher dim representations to capture pattersn in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038020e",
   "metadata": {},
   "source": [
    "**Input Graph:**\n",
    "- Node features (x): `[num_nodes, node_feat_dim]`\n",
    "- Edge index (edge_index): `[2, num_edges]`\n",
    "- Edge features (edge_attr): `[num_edges, edge_feat_dim]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d302b8",
   "metadata": {},
   "source": [
    "**Layers:**\n",
    "- `EdgeConv` captures local patterns in the graph by considering the relationships between a node and its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3c9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeClassificationGNN(nn.Module):\n",
    "    def __init__(self, node_feat_dim, hidden_dim, edge_feat_dim, out_dim=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node_feat_dim (int): Dimensionality of node features (1 in this case).\n",
    "            hidden_dim (int): Hidden layer dimension.\n",
    "            edge_feat_dim (int): Dimensionality of edge features (1 for prize).\n",
    "            out_dim (int): Output dimension (1 for binary classification).\n",
    "        \"\"\"\n",
    "        super(EdgeClassificationGNN, self).__init__()\n",
    "        \n",
    "        # --- First Layer: EdgeConv ---\n",
    "        # PURPOSE: updates the features of each node by aggregating information from its direct neighbors.\n",
    "        # MLP takes the concatenated features of a node and its neighbor --> outputs new feature vector\n",
    "        self.mlp_edgeconv = nn.Sequential(\n",
    "            nn.Linear(2 * node_feat_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        # resutls from all neighbors are aggregated - \n",
    "        # 'max' selects the most important feature for each dimension\n",
    "        self.conv1 = EdgeConv(nn=self.mlp_edgeconv, aggr='max')\n",
    "        \n",
    "        # --- Second Layer: NNConv ---\n",
    "        # PURPOSE: updates node features by incorporating edge-specific information\n",
    "        # MLP maps edge features to weight matrix --> which transforms the neighboring node features\n",
    "        self.edge_nn = nn.Sequential(\n",
    "            nn.Linear(edge_feat_dim, hidden_dim * hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        # transformed features from all neighbors aggregated by averaging contriutions from all neihbors\n",
    "        self.conv2 = NNConv(in_channels=hidden_dim,\n",
    "                            out_channels=hidden_dim,\n",
    "                            nn=self.edge_nn,\n",
    "                            aggr='mean')\n",
    "        \n",
    "        # --- Final Edge Classifier ---\n",
    "        # combine the features of the source node, target node, and edge to predict the edge label\n",
    "        # classifier is mlp that takes concatenated features and outputs raw score i.e. logit for binary classification\n",
    "        self.edge_classifier = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim + edge_feat_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # input node features and edge index into edge conv\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # input updated node features, edge index (edge_index), and edge features (edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        # for edge classification\n",
    "        src, dst = edge_index\n",
    "        edge_representation = torch.cat([x[src], x[dst], edge_attr], dim=1)\n",
    "        logits = self.edge_classifier(edge_representation)\n",
    "        # return raw logits instead of probabilities\n",
    "        return logits  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2630d50",
   "metadata": {},
   "source": [
    "### Training Setup & Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd4ce9",
   "metadata": {},
   "source": [
    "- initialize model, loss function, and optimizer\n",
    "- `BCEWithLogitsLoss` loss function is chosen for binary classification - binary CEL with logitcs i.e raw scores\n",
    "- `Adam` optimizer users to update model parameters during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 8 # dimension of hidden layer\n",
    "node_feat_dim = 1 # dimension of node features\n",
    "edge_feat_dim = 1 # dimension of edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7e38a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EdgeClassificationGNN(node_feat_dim, hidden_dim, edge_feat_dim)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80be6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use class weighting in the loss function - assign higher weight to positive class i.e. minority class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad95b0",
   "metadata": {},
   "source": [
    "- train the model using the following loop function \n",
    "- update model params to minimize loss functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159545b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=20):\n",
    "    model.train()  # set the model to training mode bc of layers beaviours\n",
    "    # epoch loop:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)  # move batch to the GPU\n",
    "            # clear grads from previous batch\n",
    "            optimizer.zero_grad()  \n",
    "            # forward pass + get model predictions based on input batch\n",
    "            out = model(batch) \n",
    "            # compute loss by comparing model pred (out) to ground truth labels\n",
    "            loss = criterion(out, batch.y)  \n",
    "            # compute grads wrt model params - backprop\n",
    "            loss.backward()  \n",
    "            # update model params using computed gradients - optimization\n",
    "            optimizer.step() \n",
    "            # accumulate loss for current epoch\n",
    "            epoch_loss += loss.item()  # Accumulate loss    \n",
    "        # print average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b907b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjeevs/.local/lib/python3.10/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 1.0668\n",
      "Epoch 2/7, Loss: 0.6027\n",
      "Epoch 3/7, Loss: 0.3637\n",
      "Epoch 4/7, Loss: 0.2581\n",
      "Epoch 5/7, Loss: 0.2034\n",
      "Epoch 6/7, Loss: 0.1586\n",
      "Epoch 7/7, Loss: 0.1394\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "train(model, train_loader, epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961db6b",
   "metadata": {},
   "source": [
    "### Overall: Evaluation & Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc582ff5",
   "metadata": {},
   "source": [
    "- Evaluates the model's performance using precision, recall, F1-score, and AUC-ROC.\n",
    "- These metrics provide a comprehensive assessment of the model's classification performance, especially important for imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244b78b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node1</th>\n",
       "      <th>Node2</th>\n",
       "      <th>Prize</th>\n",
       "      <th>Directionality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>BGAT_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>KAD3_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>ALG13_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>ALG14_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>ALG5_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Node1        Node2  Prize Directionality\n",
       "0  A4GAT_HUMAN   BGAT_HUMAN   0.75              D\n",
       "1  A4GAT_HUMAN   KAD3_HUMAN   0.75              D\n",
       "2  A4GAT_HUMAN  ALG13_HUMAN   0.75              D\n",
       "3  A4GAT_HUMAN  ALG14_HUMAN   0.75              D\n",
       "4  A4GAT_HUMAN   ALG5_HUMAN   0.75              D"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the y_true from the bulk processed pathway\n",
    "bulk_pc_processed = pd.read_csv('processed-bulk-pc-pathway.txt', sep='\\t')\n",
    "bulk_pc_processed.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "bulk_pc_processed.rename(columns={'0':'Node1','1':'Node2','2':'Prize','3':'Directionality'}, inplace=True)\n",
    "bulk_pc_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83a59b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_edges = set()\n",
    "for _, row in bulk_pc_processed.iterrows():\n",
    "    a, b = row['Node1'], row['Node2']\n",
    "    gold_edges.add(tuple(sorted((a, b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c44e4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bulk_metrics(model, dataset, device,\n",
    "                          inv_label_map, gold_edges):\n",
    "    model.eval()\n",
    "    y_true_all, y_pred_all, y_score_all = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            data = data.to(device)\n",
    "            logits = model(data)                        # [num_edges, 1]\n",
    "            probs  = torch.sigmoid(logits).view(-1).cpu().numpy()\n",
    "            preds  = (logits > 0).view(-1).float().cpu().numpy()\n",
    "\n",
    "            # Re-build y_true from gold_edges:\n",
    "            src = data.edge_index[0].cpu().numpy()\n",
    "            dst = data.edge_index[1].cpu().numpy()\n",
    "            y_true = [\n",
    "                1 if tuple(sorted((\n",
    "                    inv_label_map[int(u)],\n",
    "                    inv_label_map[int(v)]\n",
    "                ))) in gold_edges else 0\n",
    "                for u, v in zip(src, dst)\n",
    "            ]\n",
    "\n",
    "            y_true_all.extend(y_true)\n",
    "            y_pred_all.extend(preds)\n",
    "            y_score_all.extend(probs)\n",
    "\n",
    "    precision = precision_score(y_true_all, y_pred_all)\n",
    "    recall    = recall_score(y_true_all, y_pred_all)\n",
    "    f1        = f1_score(y_true_all, y_pred_all)\n",
    "    roc_auc   = roc_auc_score(y_true_all, y_score_all)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}, \"\n",
    "          f\"Recall:    {recall:.4f}, \"\n",
    "          f\"F1:        {f1:.4f}, \"\n",
    "          f\"AUC-ROC:   {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3248e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9307, Recall:    0.0077, F1:        0.0152, AUC-ROC:   0.2449\n"
     ]
    }
   ],
   "source": [
    "evaluate_bulk_metrics(model, test_dataset, device, inv_label_map, gold_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7acfec",
   "metadata": {},
   "source": [
    "**Plotting PRC:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffa24d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bulk_prc(model, dataset, device):\n",
    "    model.eval()\n",
    "    y_true_all, y_score_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            data = data.to(device)\n",
    "            probs = torch.sigmoid(model(data)).view(-1).cpu().numpy()\n",
    "\n",
    "            # same gold-based y_true:\n",
    "            src = data.edge_index[0].cpu().numpy()\n",
    "            dst = data.edge_index[1].cpu().numpy()\n",
    "            for u, v, p in zip(src, dst, probs):\n",
    "                lu = inv_label_map[int(u)]\n",
    "                lv = inv_label_map[int(v)]\n",
    "                y_true_all.append(\n",
    "                    1 if tuple(sorted((lu, lv))) in gold_edges else 0\n",
    "                )\n",
    "                y_score_all.append(p)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_all, y_score_all)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, marker='.', label='PR Curve (bulk)')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Bulk Precisionâ€“Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3fcc8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bulk_prc(model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95386b09",
   "metadata": {},
   "source": [
    "### Validate Prediction with Test Pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef475f2b",
   "metadata": {},
   "source": [
    "**Extract single graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9561fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test_data = test_dataset[-2].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79f3c588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17407, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_test_data.x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7c3c9",
   "metadata": {},
   "source": [
    "**Run model forward pass for single test graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1097aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(single_test_data)\n",
    "    y_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    y_true = single_test_data.y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61c392",
   "metadata": {},
   "source": [
    "**Identify TP/FP/FN edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e316943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mask = (y_true == 1) & (y_pred == 1)\n",
    "fp_mask = (y_true == 0) & (y_pred == 1)\n",
    "fn_mask = (y_true == 1) & (y_pred == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd0fa592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 1\n",
      "False Positives (FP): 136\n",
      "False Negatives (FN): 0\n"
     ]
    }
   ],
   "source": [
    "num_tp = np.sum(tp_mask)\n",
    "num_fp = np.sum(fp_mask)\n",
    "num_fn = np.sum(fn_mask)\n",
    "\n",
    "print(f\"True Positives (TP): {num_tp}\")\n",
    "print(f\"False Positives (FP): {num_fp}\")\n",
    "print(f\"False Negatives (FN): {num_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa968ab",
   "metadata": {},
   "source": [
    "**Convert to NetworkX graph (only plot TP/FP/FN edges)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e241085",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = single_test_data.edge_index.cpu().numpy()\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09cbf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add only TP/FP/FN edges to reduce clutter\n",
    "for i, (src, dst) in enumerate(edge_index.T):\n",
    "    if tp_mask[i] or fp_mask[i] or fn_mask[i]:\n",
    "        G.add_edge(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a53e1",
   "metadata": {},
   "source": [
    "**Assign edge colors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38bfa01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_colors = []\n",
    "for i, (src, dst) in enumerate(edge_index.T):\n",
    "    if tp_mask[i]:\n",
    "        # TP -> green\n",
    "        edge_colors.append(\"green\")  \n",
    "    elif fp_mask[i]:\n",
    "        # FP -> red\n",
    "        edge_colors.append(\"red\")    \n",
    "    elif fn_mask[i]:\n",
    "        # FN -> blue\n",
    "        edge_colors.append(\"blue\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fac59",
   "metadata": {},
   "source": [
    "**Draw the graph (only TP/FP/FN edges)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dd0cab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 10))\n",
    "# pos = nx.spring_layout(G, k=0.15, iterations=50)  # Force-directed layout\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     edge_color=edge_colors,\n",
    "#     node_size=20,\n",
    "#     node_color=\"lightgray\",\n",
    "#     width=1.0,\n",
    "#     with_labels=False,\n",
    "# )\n",
    "# plt.title(\"Network: TP (Green), FP (Red), FN (Blue)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788455aa",
   "metadata": {},
   "source": [
    "**Print metrics for this graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7adcde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "# recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "# f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "# print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e3943",
   "metadata": {},
   "source": [
    "### Compute PRC for each `Data` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f4d2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prc_for_dataset(model, dataset, device):\n",
    "    model.eval()\n",
    "    prc_dict = {}\n",
    "\n",
    "    for data in dataset:\n",
    "        # --- 1) extract the raw prefix from the filename ---\n",
    "        raw_name = data.file_name                            \n",
    "        prefix   = raw_name.split('_train_')[0]\n",
    "\n",
    "        # --- 2) sanitize exactly as in your preprocessing script ---\n",
    "        #    replace every non-word (\\W+) with '_', strip leading/trailing '_', lowercase\n",
    "        sanitized = re.sub(r'\\W+', '_', prefix).strip('_').lower()\n",
    "        lookup_fp = os.path.join(\n",
    "            'processed-pc-individual-pathways',\n",
    "            f\"{sanitized}.txt\"\n",
    "        )\n",
    "\n",
    "        if not os.path.isfile(lookup_fp):\n",
    "            # raise FileNotFoundError(f\"No processed pathway file found at: {lookup_fp}\")\n",
    "            print(f\"No processed pathway file found at: {lookup_fp} for dataset {data.file_name}\")\n",
    "            continue\n",
    "\n",
    "        # --- 3) read in the gold-standard edges ---\n",
    "        pathway_df = pd.read_csv(lookup_fp, sep='\\t')\n",
    "\n",
    "        # --- 4) build the undirected gold-edge set ---\n",
    "        gold_edges = set()\n",
    "        for _, row in pathway_df.iterrows():\n",
    "            a, b = row['Node1'], row['Node2']\n",
    "            gold_edges.add(tuple(sorted((a, b))))\n",
    "\n",
    "        # --- 5) get model scores ---\n",
    "        with torch.no_grad():\n",
    "            logits = model(data.to(device))\n",
    "            probs  = torch.sigmoid(logits).view(-1).cpu().numpy()\n",
    "\n",
    "        # --- 6) override y_true based on gold_edges ---\n",
    "        src, dst = data.edge_index\n",
    "        src, dst = src.cpu().numpy(), dst.cpu().numpy()\n",
    "        y_true = np.array([\n",
    "            1 if tuple(sorted((inv_label_map[u], inv_label_map[v]))) in gold_edges else 0\n",
    "            for u, v in zip(src, dst)\n",
    "        ], dtype=int)\n",
    "\n",
    "        # --- 7) compute precisionâ€“recall & AP ---\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, probs)\n",
    "        ap = average_precision_score(y_true, probs)\n",
    "\n",
    "        prc_dict[raw_name] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'thresholds': thresholds,\n",
    "            'average_precision': ap,\n",
    "            'pathway_df': pathway_df\n",
    "        }\n",
    "\n",
    "    return prc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed69edc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_4029.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_4495.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_4603.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_5286.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_5476.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_6041.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_6364.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_6852.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_7496.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_1917.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_1944.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_3112.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_4541.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_6175.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_9537.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_1226.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_3085.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_4272.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_4472.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_6820.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_7576.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_9384.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_3551.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_5467.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_6589.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_7923.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_8676.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_9079.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_9534.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_9761.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_1008.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosaminoglycan_bi__1.txt for dataset glycosaminoglycan_bi__1_train_4067.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_2264.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_2271.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_4340.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__1.txt for dataset glycosphingolipid_bi__1_train_8148.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_1757.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_2594.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/glycosphingolipid_bi__2.txt for dataset glycosphingolipid_bi__2_train_7608.csv\n",
      "No processed pathway file found at: processed-pc-individual-pathways/valine__leucine_and___1.txt for dataset valine__leucine_and___1_train_4437.csv\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train_prc = compute_prc_for_dataset(model, train_dataset, device)\n",
    "test_prc  = compute_prc_for_dataset(model, test_dataset,  device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cd08b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for fn, info in train_prc.items():\n",
    "    rows.append({\n",
    "      'file_name': fn,\n",
    "      'precision': info['precision'],\n",
    "      'recall': info['recall'],\n",
    "      'thresholds': info['thresholds'],\n",
    "      'average_precision': info['average_precision']\n",
    "    })\n",
    "\n",
    "train_prc_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2983b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alanine__aspartate_a_train_2535.csv</td>\n",
       "      <td>[0.0012913759833753896, 0.0012913823728780015,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0011959524, 0.0012502815, 0.001367893, 0.00...</td>\n",
       "      <td>0.191173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alanine__aspartate_a_train_3273.csv</td>\n",
       "      <td>[0.001227133505197999, 0.001227139577230623, 0...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0020992365, 0.0021502003, 0.0021812348, 0.0...</td>\n",
       "      <td>0.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alanine__aspartate_a_train_3711.csv</td>\n",
       "      <td>[0.0013012587080430652, 0.0013012780232448827,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[4.972743e-05, 0.00013231131, 0.00013245876, 0...</td>\n",
       "      <td>0.251967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alanine__aspartate_a_train_3781.csv</td>\n",
       "      <td>[0.0012469013018243354, 0.0012469074715487382,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.8217794e-05, 0.0011892465, 0.002617406, 0.0...</td>\n",
       "      <td>0.101482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alanine__aspartate_a_train_6130.csv</td>\n",
       "      <td>[0.0012419594260267195, 0.001241965571328903, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.4209523e-05, 0.0018694638, 0.001916065, 0.0...</td>\n",
       "      <td>0.130673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0  alanine__aspartate_a_train_2535.csv   \n",
       "1  alanine__aspartate_a_train_3273.csv   \n",
       "2  alanine__aspartate_a_train_3711.csv   \n",
       "3  alanine__aspartate_a_train_3781.csv   \n",
       "4  alanine__aspartate_a_train_6130.csv   \n",
       "\n",
       "                                           precision  \\\n",
       "0  [0.0012913759833753896, 0.0012913823728780015,...   \n",
       "1  [0.001227133505197999, 0.001227139577230623, 0...   \n",
       "2  [0.0013012587080430652, 0.0013012780232448827,...   \n",
       "3  [0.0012469013018243354, 0.0012469074715487382,...   \n",
       "4  [0.0012419594260267195, 0.001241965571328903, ...   \n",
       "\n",
       "                                              recall  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          thresholds  average_precision  \n",
       "0  [0.0011959524, 0.0012502815, 0.001367893, 0.00...           0.191173  \n",
       "1  [0.0020992365, 0.0021502003, 0.0021812348, 0.0...           0.078431  \n",
       "2  [4.972743e-05, 0.00013231131, 0.00013245876, 0...           0.251967  \n",
       "3  [1.8217794e-05, 0.0011892465, 0.002617406, 0.0...           0.101482  \n",
       "4  [1.4209523e-05, 0.0018694638, 0.001916065, 0.0...           0.130673  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8967eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for fn, info in test_prc.items():\n",
    "    test_rows.append({\n",
    "      'file_name': fn,\n",
    "      'precision': info['precision'],\n",
    "      'recall': info['recall'],\n",
    "      'thresholds': info['thresholds'],\n",
    "      'average_precision': info['average_precision']\n",
    "    })\n",
    "\n",
    "test_prc_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b78ab54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha_linolenic_acid_train_4939.csv</td>\n",
       "      <td>[0.00045524271364243656, 0.0004502966514753401...</td>\n",
       "      <td>[1.0, 0.9891304347826086, 0.9891304347826086, ...</td>\n",
       "      <td>[0.0016099933, 0.0030466935, 0.0030559262, 0.0...</td>\n",
       "      <td>0.073416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aminoacyl_trna_biosy_train_2796.csv</td>\n",
       "      <td>[0.0008313127814340146, 0.0008263685801800197,...</td>\n",
       "      <td>[1.0, 0.9940476190476191, 0.9940476190476191, ...</td>\n",
       "      <td>[5.7083907e-05, 0.00010559698, 0.00013245876, ...</td>\n",
       "      <td>0.091203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aminoacyl_trna_biosy_train_5354.csv</td>\n",
       "      <td>[0.0008313127814340146, 0.0008214243299948538,...</td>\n",
       "      <td>[1.0, 0.9880952380952381, 0.9880952380952381, ...</td>\n",
       "      <td>[4.0828763e-05, 9.5048046e-05, 0.00013245876, ...</td>\n",
       "      <td>0.101673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aminoacyl_trna_biosy_train_8954.csv</td>\n",
       "      <td>[0.0008313127814340146, 0.0008214243299948538,...</td>\n",
       "      <td>[1.0, 0.9880952380952381, 0.9880952380952381, ...</td>\n",
       "      <td>[3.7108697e-05, 0.0012369639, 0.0014624246, 0....</td>\n",
       "      <td>0.123547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arachidonic_acid_met_train_3652.csv</td>\n",
       "      <td>[0.0033252511257360583, 0.0033252675801255884,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0021353522, 0.0028464682, 0.0029387244, 0.0...</td>\n",
       "      <td>0.211526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0  alpha_linolenic_acid_train_4939.csv   \n",
       "1  aminoacyl_trna_biosy_train_2796.csv   \n",
       "2  aminoacyl_trna_biosy_train_5354.csv   \n",
       "3  aminoacyl_trna_biosy_train_8954.csv   \n",
       "4  arachidonic_acid_met_train_3652.csv   \n",
       "\n",
       "                                           precision  \\\n",
       "0  [0.00045524271364243656, 0.0004502966514753401...   \n",
       "1  [0.0008313127814340146, 0.0008263685801800197,...   \n",
       "2  [0.0008313127814340146, 0.0008214243299948538,...   \n",
       "3  [0.0008313127814340146, 0.0008214243299948538,...   \n",
       "4  [0.0033252511257360583, 0.0033252675801255884,...   \n",
       "\n",
       "                                              recall  \\\n",
       "0  [1.0, 0.9891304347826086, 0.9891304347826086, ...   \n",
       "1  [1.0, 0.9940476190476191, 0.9940476190476191, ...   \n",
       "2  [1.0, 0.9880952380952381, 0.9880952380952381, ...   \n",
       "3  [1.0, 0.9880952380952381, 0.9880952380952381, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          thresholds  average_precision  \n",
       "0  [0.0016099933, 0.0030466935, 0.0030559262, 0.0...           0.073416  \n",
       "1  [5.7083907e-05, 0.00010559698, 0.00013245876, ...           0.091203  \n",
       "2  [4.0828763e-05, 9.5048046e-05, 0.00013245876, ...           0.101673  \n",
       "3  [3.7108697e-05, 0.0012369639, 0.0014624246, 0....           0.123547  \n",
       "4  [0.0021353522, 0.0028464682, 0.0029387244, 0.0...           0.211526  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec328ea8",
   "metadata": {},
   "source": [
    "**Save these dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ce3d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prc_df.to_csv('test_prc_values.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "435d1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prc_df.to_csv('train_prc_values.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014b182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
