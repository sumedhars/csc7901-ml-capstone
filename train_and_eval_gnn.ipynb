{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c8b2c2",
   "metadata": {},
   "source": [
    "## GOAL: predict whether an edge (interaction) between two proteins should be included in a pathway (label 1) or not (label 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c50aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import EdgeConv, NNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae6dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7030fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f94abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to CUDA\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45e575",
   "metadata": {},
   "source": [
    "### Data Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7975f71",
   "metadata": {},
   "source": [
    "**Pytorch Geometric `DataLoader` object from saved data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f8a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique nodes: 17407\n"
     ]
    }
   ],
   "source": [
    "union_ppi = pd.read_csv('processed-data/union_ppi.txt', sep='\\t', header=None)\n",
    "unique_nodes = set(union_ppi[0].tolist() + union_ppi[1].tolist())\n",
    "label_id_map = {label: idx for idx, label in enumerate(sorted(unique_nodes))}\n",
    "num_nodes = len(label_id_map)\n",
    "print(f\"Total unique nodes: {num_nodes}\")\n",
    "\n",
    "inv_label_map = {idx: label for label, idx in label_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60700cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = torch.load('dataset.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ce6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data objects: 820\n",
      "\n",
      "Data object 0:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 1:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 2:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 3:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n",
      "\n",
      "Data object 4:\n",
      "  Node features (x) size: torch.Size([17407, 1])\n",
      "  Edge index size: torch.Size([2, 202090])\n",
      "  Edge attributes size: torch.Size([202090, 1])\n",
      "  Edge labels (y) size: torch.Size([202090, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of data objects:\", len(data_list))\n",
    "\n",
    "for i, data in enumerate(data_list[:5]):\n",
    "    print(f\"\\nData object {i}:\")\n",
    "    print(\"  Node features (x) size:\", data.x.size())\n",
    "    print(\"  Edge index size:\", data.edge_index.size())\n",
    "    print(\"  Edge attributes size:\", data.edge_attr.size())\n",
    "    print(\"  Edge labels (y) size:\", data.y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a6c6a",
   "metadata": {},
   "source": [
    "### Class Weight Calculation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e493d",
   "metadata": {},
   "source": [
    "- Calculate the weight for the positive class to handle class imbalance\n",
    "- needed since the number of negative samples (non-selected edges) is much higher than positive samples (selected edges)\n",
    "- weighting the **loss function** helps the model to learn from the minority class effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8bddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class weight: 7362.594285968186\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_weights(data_list):\n",
    "    # concat all labels into single tensor\n",
    "    y = torch.cat([data.y for data in data_list]).cpu().numpy()\n",
    "    # count the number of pos and negative samples\n",
    "    num_positive = y.sum()\n",
    "    num_negative = len(y) - num_positive\n",
    "    # calculate the weight --> ratio of negative samples to positive samples\n",
    "    # so that loss function balances the contribution of both classes\n",
    "    pos_weight = torch.tensor([num_negative / (2 * num_positive)]).to(device)\n",
    "    return pos_weight\n",
    "\n",
    "pos_weight = calculate_class_weights(data_list)\n",
    "print(f\"Positive class weight: {pos_weight.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b024a",
   "metadata": {},
   "source": [
    "### Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e89fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(data_list))\n",
    "test_size = len(data_list) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c900326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, test_dataset = random_split(data_list, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc3376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the file names from the train split\n",
    "# train_indices = train_dataset.indices \n",
    "# train_file_names = [data_list[idx].file_name for idx in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c009d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_file_names to a txt file\n",
    "# with open('train_files.txt', 'w') as f:\n",
    "#     for fname in train_file_names:\n",
    "#         f.write(f\"{fname}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37eacf6",
   "metadata": {},
   "source": [
    "### Train-test split: from existing train split file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1f9fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 656 graphs; testing on 164 graphs.\n"
     ]
    }
   ],
   "source": [
    "with open('normalized_train_files.txt') as f:\n",
    "    train_files = set(f.read().splitlines())\n",
    "\n",
    "#Partition data_list\n",
    "train_dataset = [data for data in data_list if data.file_name in train_files]\n",
    "test_dataset  = [data for data in data_list if data.file_name not in train_files]\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} graphs; testing on {len(test_dataset)} graphs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab2737",
   "metadata": {},
   "source": [
    "### Edge Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffd1b2",
   "metadata": {},
   "source": [
    "- technique that oversamples the positive edges to address class imbalance\n",
    "- duplicate positive edges in dataset to increase representation during training - so that the model sees more examples\n",
    "- oersampling helps the model to better learn the characteristics of the minority class (selected edges), improving its ability to classify them correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c7763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_sampling(data_list, sampling_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Oversample edges from the minority class (positive edges).\n",
    "    Args:\n",
    "        data_list: List of PyG data objects.\n",
    "        sampling_ratio: Ratio of minority class edges to add.\n",
    "    Returns:\n",
    "        Augmented data_list with oversampled positive edges.\n",
    "    \"\"\"\n",
    "    augmented_data_list = []\n",
    "    for data in data_list:\n",
    "        y = data.y.cpu().numpy()\n",
    "        # get the indices of positive and negtive edges\n",
    "        positive_indices = np.where(y == 1)[0]\n",
    "        negative_indices = np.where(y == 0)[0]\n",
    "        # oversample positive edges\n",
    "        num_positive = len(positive_indices)\n",
    "        # fraction of +ve edges are randomly sampled with replacement\n",
    "        num_samples = int(sampling_ratio * num_positive)\n",
    "        # stores the indices of the sampled positive edges\n",
    "        sampled_indices = np.random.choice(positive_indices, num_samples, replace=True)\n",
    "        # connectivity information (source and target nodes) for the sampled edges:\n",
    "        sampled_edge_index = data.edge_index[:, sampled_indices]\n",
    "        # edge features for sampled edges:\n",
    "        sampled_edge_attr = data.edge_attr[sampled_indices]\n",
    "        # labels for sampled edges:\n",
    "        sampled_y = data.y[sampled_indices]\n",
    "        # connectivity information is updated by concatenating the original edges and the sampled edge:\n",
    "        data.edge_index = torch.cat([data.edge_index, sampled_edge_index], dim=1)\n",
    "        # edge features are updated by concatenating the original features and the sampled features:\n",
    "        data.edge_attr = torch.cat([data.edge_attr, sampled_edge_attr], dim=0)\n",
    "        # labels are updated by concatenating the original labels and the sampled label:\n",
    "        data.y = torch.cat([data.y, sampled_y], dim=0)\n",
    "        augmented_data_list.append(data)  \n",
    "    return augmented_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3c682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply edge sampling to the training dataset\n",
    "train_dataset = edge_sampling(train_dataset, sampling_ratio=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f2d34",
   "metadata": {},
   "source": [
    "### Make DataLoader:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25b273",
   "metadata": {},
   "source": [
    "- for batching and shuffling data\n",
    "- feeds data into model during training and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005c6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe1879",
   "metadata": {},
   "source": [
    "### Model Definition: using `EdgeConv` and `NNNConv` layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82375eea",
   "metadata": {},
   "source": [
    "- define GNN for edge classification \n",
    "- architecture designed to capture both node + edge features - needed for accurately classifying edges in PPI network\n",
    "- use mlps to transform node + edge features into higher dim representations to capture pattersn in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038020e",
   "metadata": {},
   "source": [
    "**Input Graph:**\n",
    "- Node features (x): `[num_nodes, node_feat_dim]`\n",
    "- Edge index (edge_index): `[2, num_edges]`\n",
    "- Edge features (edge_attr): `[num_edges, edge_feat_dim]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d302b8",
   "metadata": {},
   "source": [
    "**Layers:**\n",
    "- `EdgeConv` captures local patterns in the graph by considering the relationships between a node and its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3c9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeClassificationGNN(nn.Module):\n",
    "    def __init__(self, node_feat_dim, hidden_dim, edge_feat_dim, out_dim=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node_feat_dim (int): Dimensionality of node features (1 in this case).\n",
    "            hidden_dim (int): Hidden layer dimension.\n",
    "            edge_feat_dim (int): Dimensionality of edge features (1 for prize).\n",
    "            out_dim (int): Output dimension (1 for binary classification).\n",
    "        \"\"\"\n",
    "        super(EdgeClassificationGNN, self).__init__()\n",
    "        \n",
    "        # --- First Layer: EdgeConv ---\n",
    "        # PURPOSE: updates the features of each node by aggregating information from its direct neighbors.\n",
    "        # MLP takes the concatenated features of a node and its neighbor --> outputs new feature vector\n",
    "        self.mlp_edgeconv = nn.Sequential(\n",
    "            nn.Linear(2 * node_feat_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        # resutls from all neighbors are aggregated - \n",
    "        # 'max' selects the most important feature for each dimension\n",
    "        self.conv1 = EdgeConv(nn=self.mlp_edgeconv, aggr='max')\n",
    "        \n",
    "        # --- Second Layer: NNConv ---\n",
    "        # PURPOSE: updates node features by incorporating edge-specific information\n",
    "        # MLP maps edge features to weight matrix --> which transforms the neighboring node features\n",
    "        self.edge_nn = nn.Sequential(\n",
    "            nn.Linear(edge_feat_dim, hidden_dim * hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        # transformed features from all neighbors aggregated by averaging contriutions from all neihbors\n",
    "        self.conv2 = NNConv(in_channels=hidden_dim,\n",
    "                            out_channels=hidden_dim,\n",
    "                            nn=self.edge_nn,\n",
    "                            aggr='mean')\n",
    "        \n",
    "        # --- Final Edge Classifier ---\n",
    "        # combine the features of the source node, target node, and edge to predict the edge label\n",
    "        # classifier is mlp that takes concatenated features and outputs raw score i.e. logit for binary classification\n",
    "        self.edge_classifier = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim + edge_feat_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # input node features and edge index into edge conv\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # input updated node features, edge index (edge_index), and edge features (edge_attr)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        # for edge classification\n",
    "        src, dst = edge_index\n",
    "        edge_representation = torch.cat([x[src], x[dst], edge_attr], dim=1)\n",
    "        logits = self.edge_classifier(edge_representation)\n",
    "        # return raw logits instead of probabilities\n",
    "        return logits  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2630d50",
   "metadata": {},
   "source": [
    "### Training Setup & Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd4ce9",
   "metadata": {},
   "source": [
    "- initialize model, loss function, and optimizer\n",
    "- `BCEWithLogitsLoss` loss function is chosen for binary classification - binary CEL with logitcs i.e raw scores\n",
    "- `Adam` optimizer users to update model parameters during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 8 # dimension of hidden layer\n",
    "node_feat_dim = 1 # dimension of node features\n",
    "edge_feat_dim = 1 # dimension of edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7e38a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EdgeClassificationGNN(node_feat_dim, hidden_dim, edge_feat_dim)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80be6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use class weighting in the loss function - assign higher weight to positive class i.e. minority class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad95b0",
   "metadata": {},
   "source": [
    "- train the model using the following loop function \n",
    "- update model params to minimize loss functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159545b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=20):\n",
    "    model.train()  # set the model to training mode bc of layers beaviours\n",
    "    # epoch loop:\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)  # move batch to the GPU\n",
    "            # clear grads from previous batch\n",
    "            optimizer.zero_grad()  \n",
    "            # forward pass + get model predictions based on input batch\n",
    "            out = model(batch) \n",
    "            # compute loss by comparing model pred (out) to ground truth labels\n",
    "            loss = criterion(out, batch.y)  \n",
    "            # compute grads wrt model params - backprop\n",
    "            loss.backward()  \n",
    "            # update model params using computed gradients - optimization\n",
    "            optimizer.step() \n",
    "            # accumulate loss for current epoch\n",
    "            epoch_loss += loss.item()  # Accumulate loss    \n",
    "        # print average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b907b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 1.0195\n",
      "Epoch 2/7, Loss: 0.4963\n",
      "Epoch 3/7, Loss: 0.3219\n",
      "Epoch 4/7, Loss: 0.2167\n",
      "Epoch 5/7, Loss: 0.1739\n",
      "Epoch 6/7, Loss: 0.1507\n",
      "Epoch 7/7, Loss: 0.1336\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "train(model, train_loader, epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961db6b",
   "metadata": {},
   "source": [
    "### Overall: Evaluation & Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc582ff5",
   "metadata": {},
   "source": [
    "- Evaluates the model's performance using precision, recall, F1-score, and AUC-ROC.\n",
    "- These metrics provide a comprehensive assessment of the model's classification performance, especially important for imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244b78b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node1</th>\n",
       "      <th>Node2</th>\n",
       "      <th>Prize</th>\n",
       "      <th>Directionality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>BGAT_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>KAD3_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>ALG13_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>ALG14_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4GAT_HUMAN</td>\n",
       "      <td>ALG5_HUMAN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Node1        Node2  Prize Directionality\n",
       "0  A4GAT_HUMAN   BGAT_HUMAN   0.75              D\n",
       "1  A4GAT_HUMAN   KAD3_HUMAN   0.75              D\n",
       "2  A4GAT_HUMAN  ALG13_HUMAN   0.75              D\n",
       "3  A4GAT_HUMAN  ALG14_HUMAN   0.75              D\n",
       "4  A4GAT_HUMAN   ALG5_HUMAN   0.75              D"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the y_true from the bulk processed pathway\n",
    "bulk_pc_processed = pd.read_csv('processed-bulk-pc-pathway.txt', sep='\\t')\n",
    "bulk_pc_processed.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "bulk_pc_processed.rename(columns={'0':'Node1','1':'Node2','2':'Prize','3':'Directionality'}, inplace=True)\n",
    "bulk_pc_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83a59b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_edges = set()\n",
    "for _, row in bulk_pc_processed.iterrows():\n",
    "    a, b = row['Node1'], row['Node2']\n",
    "    gold_edges.add(tuple(sorted((a, b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c44e4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bulk_metrics(model, dataset, device,\n",
    "                          inv_label_map, gold_edges):\n",
    "    model.eval()\n",
    "    y_true_all, y_pred_all, y_score_all = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            data = data.to(device)\n",
    "            logits = model(data)                        # [num_edges, 1]\n",
    "            probs  = torch.sigmoid(logits).view(-1).cpu().numpy()\n",
    "            preds  = (logits > 0).view(-1).float().cpu().numpy()\n",
    "\n",
    "            # Re-build y_true from gold_edges:\n",
    "            src = data.edge_index[0].cpu().numpy()\n",
    "            dst = data.edge_index[1].cpu().numpy()\n",
    "            y_true = [\n",
    "                1 if tuple(sorted((\n",
    "                    inv_label_map[int(u)],\n",
    "                    inv_label_map[int(v)]\n",
    "                ))) in gold_edges else 0\n",
    "                for u, v in zip(src, dst)\n",
    "            ]\n",
    "\n",
    "            y_true_all.extend(y_true)\n",
    "            y_pred_all.extend(preds)\n",
    "            y_score_all.extend(probs)\n",
    "\n",
    "    precision = precision_score(y_true_all, y_pred_all)\n",
    "    recall    = recall_score(y_true_all, y_pred_all)\n",
    "    f1        = f1_score(y_true_all, y_pred_all)\n",
    "    roc_auc   = roc_auc_score(y_true_all, y_score_all)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}, \"\n",
    "          f\"Recall:    {recall:.4f}, \"\n",
    "          f\"F1:        {f1:.4f}, \"\n",
    "          f\"AUC-ROC:   {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3248e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9230, Recall:    0.0121, F1:        0.0239, AUC-ROC:   0.2566\n"
     ]
    }
   ],
   "source": [
    "evaluate_bulk_metrics(model, test_dataset, device, inv_label_map, gold_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7acfec",
   "metadata": {},
   "source": [
    "**Plotting PRC:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffa24d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bulk_prc(model, dataset, device):\n",
    "    model.eval()\n",
    "    y_true_all, y_score_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            data = data.to(device)\n",
    "            probs = torch.sigmoid(model(data)).view(-1).cpu().numpy()\n",
    "\n",
    "            # same gold-based y_true:\n",
    "            src = data.edge_index[0].cpu().numpy()\n",
    "            dst = data.edge_index[1].cpu().numpy()\n",
    "            for u, v, p in zip(src, dst, probs):\n",
    "                lu = inv_label_map[int(u)]\n",
    "                lv = inv_label_map[int(v)]\n",
    "                y_true_all.append(\n",
    "                    1 if tuple(sorted((lu, lv))) in gold_edges else 0\n",
    "                )\n",
    "                y_score_all.append(p)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_all, y_score_all)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, marker='.', label='PR Curve (bulk)')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Bulk Precision–Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3fcc8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bulk_prc(model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95386b09",
   "metadata": {},
   "source": [
    "### Validate Prediction with Test Pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef475f2b",
   "metadata": {},
   "source": [
    "**Extract single graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9561fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test_data = test_dataset[-2].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79f3c588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17407, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_test_data.x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7c3c9",
   "metadata": {},
   "source": [
    "**Run model forward pass for single test graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1097aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(single_test_data)\n",
    "    y_prob = torch.sigmoid(logits).cpu().numpy()\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    y_true = single_test_data.y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61c392",
   "metadata": {},
   "source": [
    "**Identify TP/FP/FN edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e316943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mask = (y_true == 1) & (y_pred == 1)\n",
    "fp_mask = (y_true == 0) & (y_pred == 1)\n",
    "fn_mask = (y_true == 1) & (y_pred == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd0fa592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 1\n",
      "False Positives (FP): 316\n",
      "False Negatives (FN): 0\n"
     ]
    }
   ],
   "source": [
    "num_tp = np.sum(tp_mask)\n",
    "num_fp = np.sum(fp_mask)\n",
    "num_fn = np.sum(fn_mask)\n",
    "\n",
    "print(f\"True Positives (TP): {num_tp}\")\n",
    "print(f\"False Positives (FP): {num_fp}\")\n",
    "print(f\"False Negatives (FN): {num_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa968ab",
   "metadata": {},
   "source": [
    "**Convert to NetworkX graph (only plot TP/FP/FN edges)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e241085",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = single_test_data.edge_index.cpu().numpy()\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09cbf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add only TP/FP/FN edges to reduce clutter\n",
    "for i, (src, dst) in enumerate(edge_index.T):\n",
    "    if tp_mask[i] or fp_mask[i] or fn_mask[i]:\n",
    "        G.add_edge(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a53e1",
   "metadata": {},
   "source": [
    "**Assign edge colors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38bfa01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_colors = []\n",
    "for i, (src, dst) in enumerate(edge_index.T):\n",
    "    if tp_mask[i]:\n",
    "        # TP -> green\n",
    "        edge_colors.append(\"green\")  \n",
    "    elif fp_mask[i]:\n",
    "        # FP -> red\n",
    "        edge_colors.append(\"red\")    \n",
    "    elif fn_mask[i]:\n",
    "        # FN -> blue\n",
    "        edge_colors.append(\"blue\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fac59",
   "metadata": {},
   "source": [
    "**Draw the graph (only TP/FP/FN edges)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dd0cab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 10))\n",
    "# pos = nx.spring_layout(G, k=0.15, iterations=50)  # Force-directed layout\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     edge_color=edge_colors,\n",
    "#     node_size=20,\n",
    "#     node_color=\"lightgray\",\n",
    "#     width=1.0,\n",
    "#     with_labels=False,\n",
    "# )\n",
    "# plt.title(\"Network: TP (Green), FP (Red), FN (Blue)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788455aa",
   "metadata": {},
   "source": [
    "**Print metrics for this graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7adcde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "# recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "# f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "# print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e3943",
   "metadata": {},
   "source": [
    "### Compute PRC for each `Data` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f4d2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prc_for_dataset(model, dataset, device):\n",
    "    model.eval()\n",
    "    prc_dict = {}\n",
    "\n",
    "    for data in dataset:\n",
    "        # --- 1) extract the raw prefix from the filename ---\n",
    "        raw_name = data.file_name                            \n",
    "        prefix   = raw_name.split('_train_')[0]\n",
    "\n",
    "        # --- 2) sanitize exactly as in your preprocessing script ---\n",
    "        #    replace every non-word (\\W+) with '_', strip leading/trailing '_', lowercase\n",
    "        sanitized = re.sub(r'\\W+', '_', prefix).strip('_').lower()\n",
    "        lookup_fp = os.path.join(\n",
    "            'processed-pc-individual-pathways',\n",
    "            f\"{sanitized}.txt\"\n",
    "        )\n",
    "\n",
    "        if not os.path.isfile(lookup_fp):\n",
    "            # raise FileNotFoundError(f\"No processed pathway file found at: {lookup_fp}\")\n",
    "            print(f\"No processed pathway file found at: {lookup_fp} for dataset {data.file_name}\")\n",
    "            continue\n",
    "\n",
    "        # --- 3) read in the gold-standard edges ---\n",
    "        pathway_df = pd.read_csv(lookup_fp, sep='\\t')\n",
    "\n",
    "        # --- 4) build the undirected gold-edge set ---\n",
    "        gold_edges = set()\n",
    "        for _, row in pathway_df.iterrows():\n",
    "            a, b = row['Node1'], row['Node2']\n",
    "            gold_edges.add(tuple(sorted((a, b))))\n",
    "\n",
    "        # --- 5) get model scores ---\n",
    "        with torch.no_grad():\n",
    "            logits = model(data.to(device))\n",
    "            probs  = torch.sigmoid(logits).view(-1).cpu().numpy()\n",
    "\n",
    "        # --- 6) override y_true based on gold_edges ---\n",
    "        src, dst = data.edge_index\n",
    "        src, dst = src.cpu().numpy(), dst.cpu().numpy()\n",
    "        y_true = np.array([\n",
    "            1 if tuple(sorted((inv_label_map[u], inv_label_map[v]))) in gold_edges else 0\n",
    "            for u, v in zip(src, dst)\n",
    "        ], dtype=int)\n",
    "\n",
    "        # --- 7) compute precision–recall & AP ---\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, probs)\n",
    "        ap = average_precision_score(y_true, probs)\n",
    "\n",
    "        prc_dict[raw_name] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'thresholds': thresholds,\n",
    "            'average_precision': ap,\n",
    "            'pathway_df': pathway_df\n",
    "        }\n",
    "\n",
    "    return prc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed69edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "train_prc = compute_prc_for_dataset(model, train_dataset, device)\n",
    "test_prc  = compute_prc_for_dataset(model, test_dataset,  device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cd08b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for fn, info in train_prc.items():\n",
    "    rows.append({\n",
    "      'file_name': fn,\n",
    "      'precision': info['precision'],\n",
    "      'recall': info['recall'],\n",
    "      'thresholds': info['thresholds'],\n",
    "      'average_precision': info['average_precision']\n",
    "    })\n",
    "\n",
    "train_prc_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2983b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alanine__aspartate_a_train_2535.csv</td>\n",
       "      <td>[0.0012913759833753896, 0.0012913823728780015,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0037633253, 0.0037796106, 0.0038461706, 0.0...</td>\n",
       "      <td>0.209535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alanine__aspartate_a_train_3273.csv</td>\n",
       "      <td>[0.001227133505197999, 0.001227139577230623, 0...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0038300469, 0.0038461706, 0.0038692183, 0.0...</td>\n",
       "      <td>0.094234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alanine__aspartate_a_train_3711.csv</td>\n",
       "      <td>[0.0013012587080430652, 0.0013012651463799596,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0031356884, 0.0033304729, 0.003514468, 0.00...</td>\n",
       "      <td>0.253766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alanine__aspartate_a_train_3781.csv</td>\n",
       "      <td>[0.0012469013018243354, 0.0012469074715487382,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00433287, 0.0044043283, 0.0044560856, 0.004...</td>\n",
       "      <td>0.120355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alanine__aspartate_a_train_6130.csv</td>\n",
       "      <td>[0.0012419594260267195, 0.001241965571328903, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0031356884, 0.0033304729, 0.003514468, 0.00...</td>\n",
       "      <td>0.156261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0  alanine__aspartate_a_train_2535.csv   \n",
       "1  alanine__aspartate_a_train_3273.csv   \n",
       "2  alanine__aspartate_a_train_3711.csv   \n",
       "3  alanine__aspartate_a_train_3781.csv   \n",
       "4  alanine__aspartate_a_train_6130.csv   \n",
       "\n",
       "                                           precision  \\\n",
       "0  [0.0012913759833753896, 0.0012913823728780015,...   \n",
       "1  [0.001227133505197999, 0.001227139577230623, 0...   \n",
       "2  [0.0013012587080430652, 0.0013012651463799596,...   \n",
       "3  [0.0012469013018243354, 0.0012469074715487382,...   \n",
       "4  [0.0012419594260267195, 0.001241965571328903, ...   \n",
       "\n",
       "                                              recall  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          thresholds  average_precision  \n",
       "0  [0.0037633253, 0.0037796106, 0.0038461706, 0.0...           0.209535  \n",
       "1  [0.0038300469, 0.0038461706, 0.0038692183, 0.0...           0.094234  \n",
       "2  [0.0031356884, 0.0033304729, 0.003514468, 0.00...           0.253766  \n",
       "3  [0.00433287, 0.0044043283, 0.0044560856, 0.004...           0.120355  \n",
       "4  [0.0031356884, 0.0033304729, 0.003514468, 0.00...           0.156261  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8967eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for fn, info in test_prc.items():\n",
    "    test_rows.append({\n",
    "      'file_name': fn,\n",
    "      'precision': info['precision'],\n",
    "      'recall': info['recall'],\n",
    "      'thresholds': info['thresholds'],\n",
    "      'average_precision': info['average_precision']\n",
    "    })\n",
    "\n",
    "test_prc_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b78ab54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha_linolenic_acid_train_4939.csv</td>\n",
       "      <td>[0.00045524271364243656, 0.0004552494717621618...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.00433287, 0.0043786746, 0.0044043283, 0.004...</td>\n",
       "      <td>0.075108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aminoacyl_trna_biosy_train_2796.csv</td>\n",
       "      <td>[0.0008313127814340146, 0.0008313168950313971,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0037931562, 0.0037955283, 0.003818816, 0.00...</td>\n",
       "      <td>0.127089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aminoacyl_trna_biosy_train_5354.csv</td>\n",
       "      <td>[0.0008313127814340146, 0.0008313168950313971,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.003814849, 0.0038748754, 0.003935495, 0.004...</td>\n",
       "      <td>0.138078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aminoacyl_trna_biosy_train_8954.csv</td>\n",
       "      <td>[0.0008313127814340146, 0.0008313168950313971,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0037931562, 0.003818816, 0.0038276152, 0.00...</td>\n",
       "      <td>0.142189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arachidonic_acid_met_train_3652.csv</td>\n",
       "      <td>[0.0033252511257360583, 0.0033252675801255884,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0041879155, 0.004261291, 0.004310343, 0.004...</td>\n",
       "      <td>0.197289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0  alpha_linolenic_acid_train_4939.csv   \n",
       "1  aminoacyl_trna_biosy_train_2796.csv   \n",
       "2  aminoacyl_trna_biosy_train_5354.csv   \n",
       "3  aminoacyl_trna_biosy_train_8954.csv   \n",
       "4  arachidonic_acid_met_train_3652.csv   \n",
       "\n",
       "                                           precision  \\\n",
       "0  [0.00045524271364243656, 0.0004552494717621618...   \n",
       "1  [0.0008313127814340146, 0.0008313168950313971,...   \n",
       "2  [0.0008313127814340146, 0.0008313168950313971,...   \n",
       "3  [0.0008313127814340146, 0.0008313168950313971,...   \n",
       "4  [0.0033252511257360583, 0.0033252675801255884,...   \n",
       "\n",
       "                                              recall  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          thresholds  average_precision  \n",
       "0  [0.00433287, 0.0043786746, 0.0044043283, 0.004...           0.075108  \n",
       "1  [0.0037931562, 0.0037955283, 0.003818816, 0.00...           0.127089  \n",
       "2  [0.003814849, 0.0038748754, 0.003935495, 0.004...           0.138078  \n",
       "3  [0.0037931562, 0.003818816, 0.0038276152, 0.00...           0.142189  \n",
       "4  [0.0041879155, 0.004261291, 0.004310343, 0.004...           0.197289  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec328ea8",
   "metadata": {},
   "source": [
    "**Save these dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ce3d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prc_df.to_csv('test_prc_values.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "435d1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prc_df.to_csv('train_prc_values.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
