{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb944d9",
   "metadata": {},
   "source": [
    "### CREATE PRECISION RECALL CURVES FOR ALL SPRAS ENSEMBLE PATHWAYS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247544db",
   "metadata": {},
   "source": [
    "- loop through all spras ensemble pathway\n",
    "    - match the ensemble pathway to the processed pc individual pathway\n",
    "    - make the prc table:\n",
    "        - remove direction from ensemble pathway\n",
    "        - add y_true column and set all rows 0\n",
    "        - if ensemble pathway has rows from processed pc individual pathway, set those y_true to 1\n",
    "        - if there are rows in processed pc individual pathway that are not in ensemble pathway, add to prc df with y_true 1 and frequency 0\n",
    "    - use prc table to make the pr curve image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a865ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d580bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pc_pathways_folder = '../processed-pc-individual-pathways'\n",
    "oi2_baseline_outputs_folder = '../oi2-baseline-outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bd9c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate found - verify manually\n",
      "drug_metab\n",
      "duplicate found - verify manually\n",
      "fatty_acid\n",
      "duplicate found - verify manually\n",
      "fatty_acid\n",
      "duplicate found - verify manually\n",
      "glycosamin\n",
      "duplicate found - verify manually\n",
      "glycosamin\n",
      "duplicate found - verify manually\n",
      "glycosphin\n",
      "duplicate found - verify manually\n",
      "glycosphin\n",
      "duplicate found - verify manually\n",
      "phenylalan\n",
      "duplicate found - verify manually\n",
      "valine__le\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "pc_processed_list = [f for f in os.listdir(processed_pc_pathways_folder) if f.endswith('.txt')]\n",
    "\n",
    "# map of cleaned base names to file names\n",
    "file_map = {}\n",
    "for filename in pc_processed_list:\n",
    "    base = filename[:10]\n",
    "    label = re.sub(r'\\W+', '_', base).strip('_')\n",
    "    if label not in file_map:\n",
    "        file_map[label] = filename\n",
    "    else:\n",
    "        print(\"duplicate found - verify manually\")\n",
    "        print(label)\n",
    "print(len(file_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffdc4bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "del file_map['drug_metab']\n",
    "del file_map['fatty_acid']\n",
    "del file_map['glycosamin']\n",
    "del file_map['glycosphin']\n",
    "del file_map['phenylalan']\n",
    "del file_map['valine__le']\n",
    "print(len(file_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52beb169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202090"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_ppi = pd.read_csv('../processed-data-files/union_ppi.txt', sep='\\t', header=None)\n",
    "union_ppi.rename(columns={0:'Node1', 1:'Node2', 3:'Prize',4:'Directionality'}, inplace=True)\n",
    "\n",
    "union_ppi_length = len(union_ppi)\n",
    "union_ppi_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16614a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching file for folder: drug_metab_1108-ml\n",
      "No matching file for folder: drug_metab_1722-ml\n",
      "No matching file for folder: drug_metab_3545-ml\n",
      "No matching file for folder: drug_metab_4503-ml\n",
      "No matching file for folder: drug_metab_5565-ml\n",
      "No matching file for folder: drug_metab_6155-ml\n",
      "No matching file for folder: drug_metab_6253-ml\n",
      "No matching file for folder: drug_metab_6262-ml\n",
      "No matching file for folder: drug_metab_7207-ml\n",
      "No matching file for folder: drug_metab_7643-ml\n",
      "No matching file for folder: drug_metab_7684-ml\n",
      "No matching file for folder: drug_metab_8702-ml\n",
      "No matching file for folder: valine__le_1008-ml\n",
      "No matching file for folder: valine__le_1385-ml\n",
      "No matching file for folder: valine__le_1950-ml\n",
      "No matching file for folder: valine__le_3551-ml\n",
      "No matching file for folder: valine__le_3704-ml\n",
      "No matching file for folder: valine__le_4369-ml\n",
      "No matching file for folder: valine__le_5467-ml\n",
      "No matching file for folder: valine__le_6172-ml\n",
      "No matching file for folder: valine__le_6589-ml\n",
      "No matching file for folder: valine__le_7204-ml\n",
      "No matching file for folder: valine__le_7495-ml\n",
      "No matching file for folder: valine__le_7776-ml\n",
      "No matching file for folder: valine__le_7923-ml\n",
      "No matching file for folder: valine__le_8676-ml\n",
      "No matching file for folder: valine__le_9079-ml\n",
      "No matching file for folder: valine__le_9534-ml\n",
      "No matching file for folder: valine__le_9761-ml\n",
      "No matching file for folder: vitamin_b6_1544-ml\n",
      "No matching file for folder: vitamin_b6_6815-ml\n",
      "No matching file for folder: vitamin_b6_7405-ml\n"
     ]
    }
   ],
   "source": [
    "# loop through each subfolder in spras outputs dir\n",
    "for folder_name in os.listdir(oi2_baseline_outputs_folder):\n",
    "    folder_path = os.path.join(oi2_baseline_outputs_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract label from subfolder name\n",
    "        label_match = re.match(r'([a-zA-Z_]+)', folder_name)\n",
    "        if label_match:\n",
    "            label = label_match.group(1).strip('_')\n",
    "            if label in file_map:\n",
    "                src_file = os.path.join(processed_pc_pathways_folder, file_map[label])\n",
    "                dest_file = os.path.join(folder_path, file_map[label])\n",
    "                shutil.copy(src_file, dest_file)\n",
    "                # print(f\"Copied {src_file} -> {dest_file}\")\n",
    "            else:\n",
    "                print(f\"No matching file for folder: {folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2edfe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prec_results = []\n",
    "skipped_subfolders = []\n",
    "duplicate_label_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c61cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping subfolder 'drug_metab_1108-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_1722-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_3545-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_4503-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_5565-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_6155-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_6253-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_6262-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_7207-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_7643-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_7684-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'drug_metab_8702-ml': no matching .txt file with prefix 'drug_metab'\n",
      "Skipping subfolder 'valine__le_1008-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_1385-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_1950-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_3551-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_3704-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_4369-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_5467-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_6172-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_6589-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_7204-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_7495-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_7776-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_7923-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_8676-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_9079-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_9534-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'valine__le_9761-ml': no matching .txt file with prefix 'valine__le'\n",
      "Skipping subfolder 'vitamin_b6_1544-ml': no matching .txt file with prefix 'vitamin_b6'\n",
      "Skipping subfolder 'vitamin_b6_6815-ml': no matching .txt file with prefix 'vitamin_b6'\n",
      "Skipping subfolder 'vitamin_b6_7405-ml': no matching .txt file with prefix 'vitamin_b6'\n"
     ]
    }
   ],
   "source": [
    "for training_sample_subfolder in os.listdir(oi2_baseline_outputs_folder):\n",
    "    # get subfolder \n",
    "    folder_path = os.path.join(oi2_baseline_outputs_folder, training_sample_subfolder)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "\n",
    "        # get the matching processed pc pathway\n",
    "        prefix = training_sample_subfolder[:10]\n",
    "        matched_pc_pathway = None\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.startswith(prefix) and file_name.endswith(\".txt\"):\n",
    "                matched_pc_pathway = os.path.join(folder_path, file_name)\n",
    "                break  \n",
    "        # if there's no matching pc pathway, report and skip\n",
    "        if not matched_pc_pathway or not os.path.isfile(matched_pc_pathway):\n",
    "            print(f\"Skipping subfolder '{training_sample_subfolder}': no matching .txt file with prefix '{prefix}'\")\n",
    "            skipped_subfolders.append(training_sample_subfolder)\n",
    "            continue\n",
    "\n",
    "        pc_df = pd.read_csv(matched_pc_pathway, sep=\"\\t\")\n",
    "        # get ensemble pathway file \n",
    "        file_path = os.path.join(folder_path, \"ensemble-pathway.txt\")\n",
    "        if os.path.isfile(file_path):\n",
    "            ensemble_df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "        # MAKE THE PRC TABLE:\n",
    "        ensemble_df.drop(columns=['Direction'], inplace=True)\n",
    "        ensemble_df['y_true'] = 0\n",
    "        # comparing ensemble df to pathway commons --> set y_true to 1 and freq to 0 for missing pairs\n",
    "        pc_ytrue_pairs = set(zip(pc_df['Node1'], pc_df['Node2']))\n",
    "        ensemble_df.loc[ensemble_df[['Node1', 'Node2']].apply(tuple, axis=1).isin(pc_ytrue_pairs), 'y_true'] = 1\n",
    "        pc_missing_pairs = pc_ytrue_pairs.difference(zip(ensemble_df['Node1'], ensemble_df['Node2']))\n",
    "        if pc_missing_pairs:                      \n",
    "            new_rows = pd.DataFrame(list(pc_missing_pairs), columns=['Node1', 'Node2'])\n",
    "            new_rows['Frequency'] = 0          \n",
    "            new_rows['y_true']   = 1\n",
    "            prc_df = pd.concat([ensemble_df, new_rows], ignore_index=True)\n",
    "        # comparing ensemble df to union ppi --> set y_true to 0 and freq to 0 for missing pairs\n",
    "        union_ppi_pairs = set(zip(union_ppi['Node1'], union_ppi['Node2']))\n",
    "        ensemble_pairs  = set(zip(ensemble_df['Node1'],  ensemble_df['Node2']))\n",
    "        union_missing_pairs = union_ppi_pairs.difference(ensemble_pairs)\n",
    "        missing_df = pd.DataFrame(list(union_missing_pairs), columns=['Node1','Node2'])\n",
    "        missing_df['y_true'] = 0\n",
    "        missing_df['Frequency']   = 0\n",
    "        prc_df = pd.concat([prc_df, missing_df], ignore_index=True)\n",
    "        #print(prc_df)\n",
    "\n",
    "        # calculate prevalence --> probability of randomly drawing a positive example from your dataset\n",
    "        # num positives --> taken from pathwaycommons individual\n",
    "        num_pos = len(pc_df)\n",
    "        prevalence = num_pos/union_ppi_length\n",
    "\n",
    "        # calculate avg precision score and add to df, make new row\n",
    "        ap = average_precision_score(prc_df['y_true'], prc_df['Frequency'])\n",
    "        trimmed = os.path.basename(matched_pc_pathway)\n",
    "        avg_prec_results.append({\n",
    "        'Sample': trimmed,\n",
    "        'AveragePrecision': ap,\n",
    "        'dataset_label': training_sample_subfolder\n",
    "        })\n",
    "    \n",
    "        # plot and save precision recall curve\n",
    "        precision, recall, _ = precision_recall_curve(prc_df['y_true'], prc_df['Frequency'])\n",
    "        plt.figure()\n",
    "        plt.plot(recall, precision, linewidth=2)\n",
    "        # add prevalence as a horizontal dotted line\n",
    "        plt.axhline(prevalence, color='gray', linestyle='--', label=f'Prevalence = {prevalence:.5f}')\n",
    "        # force both axes from 0 to 1\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curve for {training_sample_subfolder}')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='lower left')\n",
    "        clean_name = training_sample_subfolder.replace('-ml', '')\n",
    "        save_path = os.path.join('../spras-baseline-eval-prc', f\"{clean_name}_prc_curve.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    \n",
    "avg_prec_df = pd.DataFrame(avg_prec_results)\n",
    "# out_path = os.path.join('../processed-data-files', 'oi2_summary_ap_scores.csv')\n",
    "# avg_prec_df.to_csv(out_path, index=False, sep='\\t')\n",
    "# print(f\"Wrote summary of average-precision scores to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1daf5b7",
   "metadata": {},
   "source": [
    "#### if the label has multiple matches to processed pc pathway, need to manually create PRC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbaa50c",
   "metadata": {},
   "source": [
    "map the skipped subfolders to its node file using the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee8be19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drug_metab_3545-ml': 'drug_metabolism___cy.txt', 'drug_metab_4503-ml': 'drug_metabolism___cy.txt', 'drug_metab_6262-ml': 'drug_metabolism___cy.txt', 'drug_metab_7207-ml': 'drug_metabolism___cy.txt', 'drug_metab_7643-ml': 'drug_metabolism___cy.txt', 'drug_metab_7684-ml': 'drug_metabolism___cy.txt', 'drug_metab_1108-ml': 'drug_metabolism___ot.txt', 'drug_metab_1722-ml': 'drug_metabolism___ot.txt', 'drug_metab_5565-ml': 'drug_metabolism___ot.txt', 'drug_metab_6155-ml': 'drug_metabolism___ot.txt', 'drug_metab_6253-ml': 'drug_metabolism___ot.txt', 'drug_metab_8702-ml': 'drug_metabolism___ot.txt', 'valine__le_1385-ml': 'valine__leucine_and.txt', 'valine__le_1950-ml': 'valine__leucine_and.txt', 'valine__le_3704-ml': 'valine__leucine_and.txt', 'valine__le_4369-ml': 'valine__leucine_and.txt', 'valine__le_6172-ml': 'valine__leucine_and.txt', 'valine__le_7204-ml': 'valine__leucine_and.txt', 'valine__le_7495-ml': 'valine__leucine_and.txt', 'valine__le_7776-ml': 'valine__leucine_and.txt', 'valine__le_1008-ml': 'valine__leucine_and___1.txt', 'valine__le_3551-ml': 'valine__leucine_and___1.txt', 'valine__le_5467-ml': 'valine__leucine_and___1.txt', 'valine__le_6589-ml': 'valine__leucine_and___1.txt', 'valine__le_7923-ml': 'valine__leucine_and___1.txt', 'valine__le_8676-ml': 'valine__leucine_and___1.txt', 'valine__le_9079-ml': 'valine__leucine_and___1.txt', 'valine__le_9534-ml': 'valine__leucine_and___1.txt', 'valine__le_9761-ml': 'valine__leucine_and___1.txt', 'vitamin_b6_1544-ml': 'vitamin_b6_metabolis.txt', 'vitamin_b6_6815-ml': 'vitamin_b6_metabolis.txt', 'vitamin_b6_7405-ml': 'vitamin_b6_metabolis.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Load the YAML config\n",
    "with open(\"../processed-data-files/datasets_config.txt\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Build a lookup from label → node_files[0]\n",
    "label_to_nodefile = {}\n",
    "for ds in cfg.get(\"datasets\", []):\n",
    "    label = ds.get(\"label\")\n",
    "    label = label + \"-ml\"\n",
    "    if label in skipped_subfolders:\n",
    "        # grab the first node file, or None if the list is empty\n",
    "        node_files = ds.get(\"node_files\", [])\n",
    "        if node_files:\n",
    "            pc_pathway = str(node_files[0])[:-21] + '.txt'\n",
    "            label_to_nodefile[label] = pc_pathway\n",
    "        else:\n",
    "            label_to_nodefile[label] = None\n",
    "\n",
    "# Now `label_to_nodefile` holds your desired map\n",
    "print(label_to_nodefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b201e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote summary of average-precision scores to ../processed-data-files\\oi2_summary_ap_scores.csv\n"
     ]
    }
   ],
   "source": [
    "for label, nodefile in label_to_nodefile.items():\n",
    "    if nodefile is None:\n",
    "        print(f\"{label!r} has no node file, skipping.\")\n",
    "        continue\n",
    "    # get the matching processed pc pathway\n",
    "    training_sample_subfolder = label\n",
    "    oi2_baseline_outputs_folder = '../oi2-baseline-outputs'\n",
    "    folder_path = os.path.join(oi2_baseline_outputs_folder, training_sample_subfolder)\n",
    "    matched_pc_pathway = '../processed-pc-individual-pathways/' + nodefile\n",
    "    pc_df = pd.read_csv(matched_pc_pathway, sep='\\t')\n",
    "\n",
    "    # get ensemble pathway file \n",
    "    file_path = os.path.join(folder_path, \"ensemble-pathway.txt\")\n",
    "    if os.path.isfile(file_path):\n",
    "        ensemble_df = pd.read_csv(file_path, sep='\\t')\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Could not find {file_path}\")\n",
    "\n",
    "    # MAKE THE PRC TABLE:\n",
    "    ensemble_df = ensemble_df.drop(columns=['Direction'])\n",
    "    ensemble_df['y_true'] = 0\n",
    "\n",
    "    # mark true positives from PC\n",
    "    pc_ytrue_pairs = set(zip(pc_df['Node1'], pc_df['Node2']))\n",
    "    ensemble_df.loc[\n",
    "        ensemble_df[['Node1','Node2']].apply(tuple, axis=1).isin(pc_ytrue_pairs),\n",
    "        'y_true'\n",
    "    ] = 1\n",
    "\n",
    "    # add missing PC edges with freq=0\n",
    "    pc_missing_pairs = pc_ytrue_pairs.difference(zip(ensemble_df['Node1'], ensemble_df['Node2']))\n",
    "    if pc_missing_pairs:\n",
    "        new_rows = pd.DataFrame(list(pc_missing_pairs), columns=['Node1', 'Node2'])\n",
    "        new_rows['Frequency'] = 0\n",
    "        new_rows['y_true']   = 1\n",
    "        prc_df = pd.concat([ensemble_df, new_rows], ignore_index=True)\n",
    "    else:\n",
    "        prc_df = ensemble_df.copy()\n",
    "    # add missing union PPI edges with y_true=0, freq=0\n",
    "    union_ppi_pairs = set(zip(union_ppi['Node1'], union_ppi['Node2']))\n",
    "    ensemble_pairs  = set(zip(prc_df['Node1'], prc_df['Node2']))\n",
    "    union_missing_pairs = union_ppi_pairs.difference(ensemble_pairs)\n",
    "    if union_missing_pairs:\n",
    "        missing_df = pd.DataFrame(list(union_missing_pairs), columns=['Node1','Node2'])\n",
    "        missing_df['Frequency'] = 0\n",
    "        missing_df['y_true']    = 0\n",
    "        prc_df = pd.concat([prc_df, missing_df], ignore_index=True)\n",
    "\n",
    "    # calculate prevalence\n",
    "    num_pos    = len(pc_df)\n",
    "    prevalence = num_pos / union_ppi_length\n",
    "\n",
    "    ap = average_precision_score(prc_df['y_true'], prc_df['Frequency'])\n",
    "    trimmed = os.path.basename(matched_pc_pathway)\n",
    "    duplicate_label_results.append({\n",
    "    'Sample': trimmed,\n",
    "    'AveragePrecision': ap,\n",
    "    'dataset_label': training_sample_subfolder\n",
    "    })\n",
    "\n",
    "    # plot and save precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(prc_df['y_true'], prc_df['Frequency'])\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, linewidth=2)\n",
    "    plt.axhline(prevalence, linestyle='--', label=f'Prevalence = {prevalence:.5f}')\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for {training_sample_subfolder}')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    clean_name = training_sample_subfolder.replace('-ml', '')\n",
    "    out_dir    = '../spras-baseline-eval-prc'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    save_path  = os.path.join(out_dir, f\"{clean_name}_prc_curve.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "duplicate_label_prec_df = pd.DataFrame(duplicate_label_results)\n",
    "overall_prec_df = pd.concat([\n",
    "    avg_prec_df,\n",
    "    duplicate_label_prec_df\n",
    "], ignore_index=True)\n",
    "out_path = os.path.join('../processed-data-files', 'oi2_summary_ap_scores.csv')\n",
    "overall_prec_df.to_csv(out_path, index=False, sep='\\t')\n",
    "print(f\"Wrote summary of average-precision scores to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc99a1b",
   "metadata": {},
   "source": [
    "#### code to match the Oi2 baseline outputs (i.e. dataset label) back to the respective node file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598d79c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>AveragePrecision</th>\n",
       "      <th>dataset_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alanine__aspartate_a.txt</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>alanine__a_1510-ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alanine__aspartate_a.txt</td>\n",
       "      <td>0.023841</td>\n",
       "      <td>alanine__a_2535-ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alanine__aspartate_a.txt</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>alanine__a_3273-ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alanine__aspartate_a.txt</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>alanine__a_3711-ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alanine__aspartate_a.txt</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>alanine__a_3781-ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Sample  AveragePrecision       dataset_label\n",
       "0  alanine__aspartate_a.txt          0.016665  alanine__a_1510-ml\n",
       "1  alanine__aspartate_a.txt          0.023841  alanine__a_2535-ml\n",
       "2  alanine__aspartate_a.txt          0.020378  alanine__a_3273-ml\n",
       "3  alanine__aspartate_a.txt          0.027565  alanine__a_3711-ml\n",
       "4  alanine__aspartate_a.txt          0.005766  alanine__a_3781-ml"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(set(overall_prec_df['dataset_label'])))\n",
    "overall_prec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3354497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 337 rows; unique labels: 337\n",
      "Done! Wrote augmented CSV to ../processed-data-files/oi2_apscore_nodefile.csv\n"
     ]
    }
   ],
   "source": [
    "# ——— Parameters ———\n",
    "csv_path     = '../processed-data-files/oi2_summary_ap_scores.csv'     # the CSV with a column \"label\"\n",
    "nodes_folder = '../baseline-spras-nodes'     # folder containing *_nodes.txt\n",
    "\n",
    "suffix_pattern = re.compile(r'^(.*?)(_train_\\d+\\.txt)$')\n",
    "\n",
    "# ——— Step 1: Read the CSV ———\n",
    "df = pd.read_csv(csv_path, sep='\\t')\n",
    "print(f\"Loaded {len(df)} rows; unique labels: {df['dataset_label'].nunique()}\")\n",
    "\n",
    "# ——— Step 2: Strip the trailing \"-ml\" to get the actual label ———\n",
    "df[\"clean_label\"] = df[\"dataset_label\"].str.replace(r\"-ml$\", \"\", regex=True)\n",
    "\n",
    "# ——— Step 3: Build label→filename map ———\n",
    "label_to_file = {}\n",
    "for fname in os.listdir(nodes_folder):\n",
    "    # get the matching folder\n",
    "    match = re.search(r'_(\\d{4})_nodes\\.txt$', fname)\n",
    "    if not match:\n",
    "        print(fname)\n",
    "        continue\n",
    "    year = match.group(1)\n",
    "    base = fname[:10]\n",
    "    lbl  = re.sub(r'\\W+', '_', base).strip('_') + f\"_{year}\"\n",
    "    label_to_file[lbl] = fname\n",
    "\n",
    "# ——— Step 4: Lookup and attach ———\n",
    "df[\"node_file\"] = df[\"clean_label\"].map(label_to_file)\n",
    "\n",
    "# Report any that still didn’t match\n",
    "missing = df[df[\"node_file\"].isna()][\"dataset_label\"].unique()\n",
    "if len(missing):\n",
    "    print(f\"Warning: {len(missing)} labels still had no match. Examples: {missing[:5]}\")\n",
    "\n",
    "# ——— Step 5: Save the augmented CSV ———\n",
    "out_csv = '../processed-data-files/oi2_apscore_nodefile.csv'\n",
    "df.drop(columns=\"clean_label\").to_csv(out_csv, index=False, sep='\\t')\n",
    "print(f\"Done! Wrote augmented CSV to {out_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
